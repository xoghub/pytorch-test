{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors: The Core of PyTorch\n",
    "\n",
    "You've seen that the journey of building a neural network begins with data. Before you can design a model or start the training process, you must gather your information and prepare it in a format the model can understand. In PyTorch, that fundamental format is the **tensor**. Tensors are more than just data containers; they are optimized for the mathematical operations that power deep learning.\n",
    "\n",
    "Mastering tensors is a vital step. Many of the most common errors encountered when building models are related to tensor shapes, types, or dimensions. This lab is designed to give you a solid foundation in tensor manipulation, providing you with the skills to handle data effectively and debug issues with confidence.\n",
    "\n",
    "In this lab, you will learn how to:\n",
    "\n",
    "* Create tensors from different data sources like Python lists and NumPy arrays.\n",
    "\n",
    "* Reshape and manipulate tensor dimensions to prepare data for model inputs.\n",
    "\n",
    "* Use indexing and slicing techniques to access and filter specific parts of your data.\n",
    "\n",
    "* Perform the mathematical and logical operations that form the basis of all neural network computations.\n",
    "\n",
    "By the end of this notebook, you will have the practical skills needed to confidently manage the data for any PyTorch project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Tensor Creation\n",
    "\n",
    "The first step in any machine learning pipeline is getting your data ready for the model. In PyTorch, this means loading your data into tensors. You will find that there are several convenient ways to create tensors, whether your data is already in another format or you need to generate it from scratch.\n",
    "\n",
    "### 1.1 From Existing Data Structures\n",
    "\n",
    "Often, your raw data will be in a common format like a Python list, a NumPy array, or a pandas DataFrame. PyTorch provides straightforward functions to convert these structures into tensors, making the data preparation stage more efficient.\n",
    "\n",
    "* `torch.tensor()`: This function takes input such as a Python list to convert it into a tensor.\n",
    "\n",
    "**Note:** The type of numbers you use matters. If you use integers, PyTorch stores them as integers. If you include decimals, they'll be stored as floating point values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From Python lists\n",
    "x = torch.tensor([1, 2, 3])\n",
    "\n",
    "print(\"FROM PYTHON LISTS:\", x)\n",
    "print(\"TENSOR DATA TYPE:\", x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* `torch.from_numpy()`: Converts a NumPy array into a PyTorch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From a NumPy array\n",
    "numpy_array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "torch_tensor_from_numpy = torch.from_numpy(numpy_array)\n",
    "\n",
    "print(\"TENSOR FROM NUMPY:\\n\\n\", torch_tensor_from_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* **From a pandas DataFrame**: Pandas is a Python library for working with data organized in rows and columns, like a CSV file or spreadsheet. A DataFrame is pandas' main data structure for storing this kind of tabular data. DataFrames are one of the most common ways to load and explore datasets in machine learning, especially when reading CSV files. There isn't a direct function to convert a DataFrame to a tensor. The standard method is to extract the data from the DataFrame into a NumPy array using the `.values` attribute, and then convert that array into a tensor using `torch.tensor()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# From Pandas DataFrame\n",
    "# Read the data from the CSV file into a DataFrame\n",
    "df = pd.read_csv('./data.csv')\n",
    "\n",
    "# Extract the data as a NumPy array from the DataFrame\n",
    "all_values = df.values\n",
    "\n",
    "# Convert the DataFrame's values to a PyTorch tensor\n",
    "tensor_from_df = torch.tensor(all_values)\n",
    "\n",
    "print(\"ORIGINAL DATAFRAME:\\n\\n\", df)\n",
    "print(\"\\nRESULTING TENSOR:\\n\\n\", tensor_from_df)\n",
    "print(\"\\nTENSOR DATA TYPE:\", tensor_from_df.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - With Predefined Values\n",
    "\n",
    "Sometimes you need to create tensors for specific purposes, like initializing a model's weights and biases before training begins. PyTorch allows you to quickly generate tensors filled with placeholder values like zeros, ones, or random numbers, which is useful for testing and setup.\n",
    "\n",
    "* `torch.zeros()`: Creates a tensor filled with zeros of the specified dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# All zeros\n",
    "zeros = torch.zeros(2, 3)\n",
    "\n",
    "print(\"TENSOR WITH ZEROS:\\n\\n\", zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* `torch.ones()`: Creates a tensor filled with ones of the specified dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# All ones\n",
    "ones = torch.ones(2, 3)\n",
    "\n",
    "print(\"TENSOR WITH ONES:\\n\\n\", ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* `torch.rand()`: Generates a tensor with random numbers uniformly distributed between 0 and 1, based on the specified dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 179,
     "status": "ok",
     "timestamp": 1739648338311,
     "user": {
      "displayName": "Laurence Moroney",
      "userId": "17858265307580721507"
     },
     "user_tz": 480
    },
    "id": "sSTgintPHYdf",
    "outputId": "329cb9e4-fc9f-4e0b-c7e7-fc82d2662bf7",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Random numbers\n",
    "random = torch.rand(2, 3)\n",
    "\n",
    "print(\"RANDOM TENSOR:\\n\\n\", random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - From a Sequence\n",
    "\n",
    "For situations where you need to generate a sequence of data points, such as a range of values for testing a model's predictions, you can create a tensor directly from that sequence.\n",
    "\n",
    "* `torch.arange()`: Creates a 1D tensor containing a range of numbers from the specified start value to one less than the specified stop value, incrementing (if positive) or decrementing (if negative) by the specified `step` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Range of numbers\n",
    "range_tensor = torch.arange(0, 10, step=1)\n",
    "\n",
    "print(\"ARANGE TENSOR:\", range_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Reshaping & Manipulating\n",
    "\n",
    "A very common source of errors in PyTorch projects is a mismatch between the shape of your input data and the shape your model expects. For instance, a model is typically designed to process a batch of data, so even if you want to make a single prediction, you must shape your input tensor to look like a batch of one. Mastering tensor reshaping is a key step toward building and debugging models effectively.\n",
    "\n",
    "### 2.1 - Checking a Tensor's Dimensions\n",
    "\n",
    "The first step to fixing a shape mismatch is to understand the current dimensions of your tensor. Checking the shape is your primary debugging tool. It tells you how many samples you have and how many features are in each sample.\n",
    "\n",
    "* `torch.Tensor.shape`: An attribute that returns a `torch.Size` object detailing the size of the tensor along each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A 2D tensor\n",
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "\n",
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"\\nTENSOR SHAPE:\", x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Changing a Tensor's Dimensions\n",
    "\n",
    "Once you identify a shape mismatch, you need to correct it. A frequent task is adding a dimension to a single data sample to create a batch of size one for your model, or removing a dimension after a batch operation is complete.\n",
    "\n",
    "* **Adding Dimension:** `torch.Tensor.unsqueeze()` inserts a new dimension at the specified index.\n",
    "    * *Notice how the shape will change from `[2, 3]` to `[1, 2, 3]` and the tensor gets wrapped in an extra pair of square brackets `[]`*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"\\nTENSOR SHAPE:\", x.shape)\n",
    "print(\"-\"*45)\n",
    "\n",
    "# Add dimension\n",
    "expanded = x.unsqueeze(0)  # Add dimension at index 0\n",
    "\n",
    "print(\"\\nTENSOR WITH ADDED DIMENSION AT INDEX 0:\\n\\n\", expanded)\n",
    "print(\"\\nTENSOR SHAPE:\", expanded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* **Removing Dimension:** `torch.Tensor.squeeze()` removes dimensions of size 1.\n",
    "    * *This reverses the unsqueeze operation, removing the `1` from the shape and taking away a pair of outer square brackets*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"EXPANDED TENSOR:\\n\\n\", expanded)\n",
    "print(\"\\nTENSOR SHAPE:\", expanded.shape)\n",
    "print(\"-\"*45)\n",
    "\n",
    "# Remove dimension\n",
    "squeezed = expanded.squeeze()\n",
    "\n",
    "print(\"\\nTENSOR WITH DIMENSION REMOVED:\\n\\n\", squeezed)\n",
    "print(\"\\nTENSOR SHAPE:\", squeezed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Restructuring\n",
    "\n",
    "Beyond just adding or removing dimensions, you may need to completely change a tensor's structure to match the requirements of a specific layer or operation within your neural network.\n",
    "\n",
    "* **Reshaping:** `torch.Tensor.reshape()` changes the shape of a tensor to the specified dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"\\nTENSOR SHAPE:\", x.shape)\n",
    "print(\"-\"*45)\n",
    "\n",
    "# Reshape\n",
    "reshaped = x.reshape(3, 2)\n",
    "\n",
    "print(\"\\nAFTER PERFORMING reshape(3, 2):\\n\\n\", reshaped)\n",
    "print(\"\\nTENSOR SHAPE:\", reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Transposing:** `torch.Tensor.transpose()` swaps the specified dimensions of a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"\\nTENSOR SHAPE:\", x.shape)\n",
    "print(\"-\"*45)\n",
    "\n",
    "# Transpose\n",
    "transposed = x.transpose(0, 1)\n",
    "\n",
    "print(\"\\nAFTER PERFORMING transpose(0, 1):\\n\\n\", transposed)\n",
    "print(\"\\nTENSOR SHAPE:\", transposed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 - Combining Tensors\n",
    "\n",
    "In the data preparation stage, you might need to combine data from different sources or merge separate batches into one larger dataset.\n",
    "\n",
    "* `torch.cat()`: Joins a sequence of tensors along an existing dimension. Note: All tensors must have the same shape in dimensions other than the one being concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create two tensors to concatenate\n",
    "tensor_a = torch.tensor([[1, 2],\n",
    "                         [3, 4]])\n",
    "tensor_b = torch.tensor([[5, 6],\n",
    "                         [7, 8]])\n",
    "\n",
    "# Concatenate along columns (dim=1)\n",
    "concatenated_tensors = torch.cat((tensor_a, tensor_b), dim=1)\n",
    "\n",
    "\n",
    "print(\"TENSOR A:\\n\\n\", tensor_a)\n",
    "print(\"\\nTENSOR B:\\n\\n\", tensor_b)\n",
    "print(\"-\"*45)\n",
    "print(\"\\nCONCATENATED TENSOR (dim=1):\\n\\n\", concatenated_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Indexing & Slicing\n",
    "\n",
    "After you have your data in a tensor, you will often need to access specific parts of it. Whether you are grabbing a single prediction to inspect its value, separating your input features from your labels, or selecting a subset of data for analysis, indexing and slicing are the tools for the job.\n",
    "\n",
    "### 3.1 - Accessing Elements\n",
    "\n",
    "These are the fundamental techniques for getting data out of a tensor, working very similarly to how you would access elements in a standard Python list.\n",
    "\n",
    "* **Standard Indexing**: Accessing single elements or entire rows using integer indices (e.g., `x[0]`, `x[1, 2]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3x4 tensor\n",
    "x = torch.tensor([\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 6, 7, 8],\n",
    "    [9, 10, 11, 12]\n",
    "])\n",
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Get a single element at row 1, column 2\n",
    "single_element_tensor = x[1, 2]\n",
    "\n",
    "print(\"\\nINDEXING SINGLE ELEMENT AT [1, 2]:\", single_element_tensor)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Get the entire second row (index 1)\n",
    "second_row = x[1]\n",
    "\n",
    "print(\"\\nINDEXING ENTIRE ROW [1]:\", second_row)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Last row\n",
    "last_row = x[-1]\n",
    "\n",
    "print(\"\\nINDEXING ENTIRE LAST ROW ([-1]):\", last_row, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* **Slicing**: Extracting sub-tensors using `[start:end:step]` notation (e.g., `x[:2, ::2]`).\n",
    "    * *Note: The `end` index itself is not included in the slice.*\n",
    "* Slicing can be used to access entire columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Get the first two rows\n",
    "first_two_rows = x[0:2]\n",
    "\n",
    "print(\"\\nSLICING FIRST TWO ROWS ([0:2]):\\n\\n\", first_two_rows)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Get the third column of all rows\n",
    "third_column = x[:, 2]\n",
    "\n",
    "print(\"\\nSLICING THIRD COLUMN ([:, 2]]):\", third_column)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Every other column\n",
    "every_other_col = x[:, ::2]\n",
    "\n",
    "print(\"\\nEVERY OTHER COLUMN ([:, ::2]):\\n\\n\", every_other_col)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Last column\n",
    "last_col = x[:, -1]\n",
    "\n",
    "print(\"\\nLAST COLUMN ([:, -1]):\", last_col, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Combining Indexing & Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Combining slicing and indexing (First two rows, last two columns)\n",
    "combined = x[0:2, 2:]\n",
    "\n",
    "print(\"\\nFIRST TWO ROWS, LAST TWO COLS ([0:2, 2:]):\\n\\n\", combined, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* **`.item()`**: Extracts the value from a single-element tensor as a standard Python number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SINGLE-ELEMENT TENSOR:\", single_element_tensor)\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Extract the value from a single-element tensor as a standard Python number\n",
    "value = single_element_tensor.item()\n",
    "\n",
    "print(\"\\n.item() PYTHON NUMBER EXTRACTED:\", value)\n",
    "print(\"TYPE:\", type(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Advanced Indexing\n",
    "\n",
    "For more complex data selection, such as filtering your dataset based on one or more conditions, you can use advanced indexing techniques.\n",
    "\n",
    "* **Boolean Masking**: Using a boolean tensor to select elements that meet a certain condition (e.g.,Â `x[x > 5]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Boolean indexing using logical comparisons\n",
    "mask = x > 6\n",
    "\n",
    "print(\"MASK (VALUES > 6):\\n\\n\", mask, \"\\n\")\n",
    "\n",
    "# Applying Boolean masking\n",
    "mask_applied = x[mask]\n",
    "\n",
    "print(\"VALUES AFTER APPLYING MASK:\", mask_applied, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* **Fancy Indexing**: Using a tensor of indices to select specific elements in a non-contiguous way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Fancy indexing\n",
    "\n",
    "# Get first and third rows\n",
    "row_indices = torch.tensor([0, 2])\n",
    "\n",
    "# Get second and fourth columns\n",
    "col_indices = torch.tensor([1, 3]) \n",
    "\n",
    "# Gets values at (0,1), (0,3), (2,1), (2,3)\n",
    "get_values = x[row_indices[:, None], col_indices]\n",
    "\n",
    "print(\"\\nSPECIFIC ELEMENTS USING INDICES:\\n\\n\", get_values, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Mathematical & Logical Operations\n",
    "\n",
    "At their core, neural networks are performing mathematical computations. A single neuron, for example, calculates a weighted sum of its inputs and adds a bias. PyTorch is optimized to perform these operations efficiently across entire tensors at once, which is what makes training so fast.\n",
    "\n",
    "### 4.1 - Arithmetic\n",
    "\n",
    "These operations are the foundation of how a neural network processes data. You'll see how PyTorch handles element-wise calculations and uses a powerful feature called broadcasting to simplify your code.\n",
    "\n",
    "* **Element-wise Operations**: Standard math operators (`+`, `*`) that apply to each element independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "print(\"TENSOR A:\", a)\n",
    "print(\"TENSOR B\", b)\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Element-wise addition\n",
    "element_add = a + b\n",
    "\n",
    "print(\"\\nAFTER PERFORMING ELEMENT-WISE ADDITION:\", element_add, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TENSOR A:\", a)\n",
    "print(\"TENSOR B\", b)\n",
    "print(\"-\" * 65)\n",
    "\n",
    "# Element-wise multiplication\n",
    "element_mul = a * b\n",
    "\n",
    "print(\"\\nAFTER PERFORMING ELEMENT-WISE MULTIPLICATION:\", element_mul, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* **Dot Product (`torch.matmul()`)**: Calculates the dot product of two vectors or matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TENSOR A:\", a)\n",
    "print(\"TENSOR B\", b)\n",
    "print(\"-\" * 65)\n",
    "\n",
    "# Dot product\n",
    "dot_product = torch.matmul(a, b)\n",
    "\n",
    "print(\"\\nAFTER PERFORMING DOT PRODUCT:\", dot_product, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* **Broadcasting**: The automatic expansion of smaller tensors to match the shape of larger tensors during arithmetic operations.\n",
    "    * Broadcasting allows operations between tensors with compatible shapes, even if they don't have the exact same dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([[1],\n",
    "                 [2],\n",
    "                 [3]])\n",
    "\n",
    "print(\"TENSOR A:\", a)\n",
    "print(\"SHAPE:\", a.shape)\n",
    "print(\"\\nTENSOR B\\n\\n\", b)\n",
    "print(\"\\nSHAPE:\", b.shape)\n",
    "print(\"-\" * 65)\n",
    "\n",
    "# Apply broadcasting\n",
    "c = a + b\n",
    "\n",
    "\n",
    "print(\"\\nTENSOR C:\\n\\n\", c)\n",
    "print(\"\\nSHAPE:\", c.shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - Logic & Comparisons\n",
    "\n",
    "Logical operations are powerful tools for data preparation and analysis. They allow you to create boolean masks to filter, select, or modify your data based on specific conditions you define.\n",
    "\n",
    "* **Comparison Operators**: Element-wise comparisons (`>`, `==`, `<`) that produce a boolean tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1739648576118,
     "user": {
      "displayName": "Laurence Moroney",
      "userId": "17858265307580721507"
     },
     "user_tz": 480
    },
    "id": "g4n6hAFsIp49",
    "outputId": "36efbe9f-62b7-4da3-f13b-c4114d6d72f3"
   },
   "outputs": [],
   "source": [
    "temperatures = torch.tensor([20, 35, 19, 35, 42])\n",
    "print(\"TEMPERATURES:\", temperatures)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "### Comparison Operators (>, <, ==)\n",
    "\n",
    "# Use '>' (greater than) to find temperatures above 30\n",
    "is_hot = temperatures > 30\n",
    "\n",
    "# Use '<=' (less than or equal to) to find temperatures 20 or below\n",
    "is_cool = temperatures <= 20\n",
    "\n",
    "# Use '==' (equal to) to find temperatures exactly equal to 35\n",
    "is_35_degrees = temperatures == 35\n",
    "\n",
    "print(\"\\nHOT (> 30 DEGREES):\", is_hot)\n",
    "print(\"COOL (<= 20 DEGREES):\", is_cool)\n",
    "print(\"EXACTLY 35 DEGREES:\", is_35_degrees, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* **Logical Operators**: Element-wise logical operations (`&` for **AND**, `|` for **OR**) on boolean tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1739649219118,
     "user": {
      "displayName": "Laurence Moroney",
      "userId": "17858265307580721507"
     },
     "user_tz": 480
    },
    "id": "hmEU32D4LDih",
    "outputId": "e4552510-be3e-4a58-b9bb-57c1344bb9ad"
   },
   "outputs": [],
   "source": [
    "is_morning = torch.tensor([True, False, False, True])\n",
    "is_raining = torch.tensor([False, False, True, True])\n",
    "print(\"IS MORNING:\", is_morning)\n",
    "print(\"IS RAINING:\", is_raining)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "### Logical Operators (&, |)\n",
    "\n",
    "# Use '&' (AND) to find when it's both morning and raining\n",
    "morning_and_raining = (is_morning & is_raining)\n",
    "\n",
    "# Use '|' (OR) to find when it's either morning or raining\n",
    "morning_or_raining = is_morning | is_raining\n",
    "\n",
    "print(\"\\nMORNING & (AND) RAINING:\", morning_and_raining)\n",
    "print(\"MORNING | (OR) RAINING:\", morning_or_raining)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 - Statistics\n",
    "\n",
    "Calculating statistics like the mean or standard deviation can be useful for understanding your dataset or for implementing certain types of normalization during the data preparation phase.\n",
    "\n",
    "* `torch.mean()`: Calculates the mean of all elements in a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor([10.0, 20.0, 30.0, 40.0, 50.0])\n",
    "print(\"DATA:\", data)\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Calculate the mean\n",
    "data_mean = data.mean()\n",
    "\n",
    "print(\"\\nCALCULATED MEAN:\", data_mean, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* `torch.std()`: Calculates the standard deviation of all elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DATA:\", data)\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Calculate the standard deviation\n",
    "data_std = data.std()\n",
    "\n",
    "print(\"\\nCALCULATED STD:\", data_std, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 - Data Types\n",
    "\n",
    "Just as important as a tensor's shape is its data type. Neural networks typically perform their calculations using 32-bit floating point numbers (float32). Providing data of the wrong type, such as an integer, can lead to runtime errors or unexpected behavior during training. It is a good practice to ensure your tensors have the correct data type for your model.\n",
    "\n",
    "* **Type Casting (`.int`, etc.)**: Converts a tensor from one data type to another (e.g., from float to integer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"DATA:\", data)\n",
    "print(\"DATA TYPE:\", data.dtype)\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Cast the tensor to a int type\n",
    "int_tensor = data.int()\n",
    "\n",
    "print(\"\\nCASTED DATA:\", int_tensor)\n",
    "print(\"CASTED DATA TYPE\", int_tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Optional Exercises\n",
    "\n",
    "You've now covered the essential tools for working with tensors in PyTorch. Theory provides the map, but hands-on practice is what builds true confidence and skill. The following optional exercises are your opportunity to apply what you have learned to practical scenarios, from analyzing sales data to engineering new features for a machine learning model. This is where the concepts truly come to life, so dive in and put your new knowledge to the test!\n",
    "\n",
    "### Exercise 1: Analyzing Monthly Sales Data\n",
    "\n",
    "You're a data analyst at an e-commerce company. You've been given a tensor representing the monthly sales of three different products over a period of four months. Your task is to extract meaningful insights from this data.\n",
    "\n",
    "The tensor `sales_data` is structured as follows:\n",
    "\n",
    "* **Rows** represent the **products** (Product A, Product B, Product C).\n",
    "\n",
    "* **Columns** represent the **months** (Jan, Feb, Mar, Apr).\n",
    "\n",
    "**Your goals are**:\n",
    "\n",
    "1. Calculate the total sales for **Product B** (the second row).\n",
    "2. Identify which months had sales **greater than 130** for **Product C** (the third row) using boolean masking.\n",
    "3. Extract the sales data for all products for the months of **Feb and Mar** (the middle two columns).\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary><span style=\"color:green;\"><strong>Solution (Click here to expand)</strong></span></summary>\n",
    "\n",
    "```python\n",
    "### START CODE HERE ###\n",
    "\n",
    "# 1. Calculate total sales for Product B.\n",
    "total_sales_product_b = sales_data[1].sum()\n",
    "\n",
    "# 2. Find months where sales for Product C were > 130.\n",
    "high_sales_mask_product_c = sales_data[2] > 130\n",
    "\n",
    "# 3. Get sales for Feb and Mar for all products.\n",
    "sales_feb_mar = sales_data[:, 1:3]\n",
    "\n",
    "### END CODE HERE ###\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sales data for 3 products over 4 months\n",
    "sales_data = torch.tensor([[100, 120, 130, 110],   # Product A\n",
    "                           [ 90,  95, 105, 125],   # Product B\n",
    "                           [140, 115, 120, 150]    # Product C\n",
    "                          ], dtype=torch.float32)\n",
    "\n",
    "print(\"ORIGINAL SALES DATA:\\n\\n\", sales_data)\n",
    "print(\"-\" * 45)\n",
    "\n",
    "### START CODE HERE ###\n",
    "\n",
    "# 1. Calculate total sales for Product B.\n",
    "total_sales_product_b = None\n",
    "\n",
    "# 2. Find months where sales for Product C were > 130.\n",
    "high_sales_mask_product_c = None\n",
    "\n",
    "# 3. Get sales for Feb and Mar for all products.\n",
    "sales_feb_mar = None\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "print(\"\\nTotal Sales for Product B:                   \", total_sales_product_b)\n",
    "print(\"\\nMonths with >130 Sales for Product C (Mask): \", high_sales_mask_product_c)\n",
    "print(\"\\nSales for Feb & Mar:\\n\\n\", sales_feb_mar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Output:\n",
    "\n",
    "```\n",
    "Total Sales for Product B:\t\t\t tensor(415.)\n",
    "\n",
    "Months with >130 Sales for Product C (Mask):\t tensor([ True, False, False,  True])\n",
    "\n",
    "Sales for Feb & Mar:\n",
    "\n",
    " tensor([[120., 130.],\n",
    "        [ 95., 105.],\n",
    "        [115., 120.]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Image Batch Transformation\n",
    "\n",
    "You're working on a computer vision model and have a batch of 4 grayscale images, each of size 3x3 pixels. The data is currently in a tensor with the shape `[4, 3, 3]`, which represents `[batch_size, height, width]`.\n",
    "\n",
    "For processing with certain deep learning frameworks, you need to transform this data into the `[batch_size, channels, height, width]` format. Since the images are grayscale, **you'll need to**:\n",
    "\n",
    "1. Add a new dimension of size 1 at index 1 to represent the color channel.\n",
    "2. After adding the channel, you realize the model expects the shape `[batch_size, height, width, channels]`. Transpose the tensor to swap the channel dimension with the last dimension.\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary><span style=\"color:green;\"><strong>Solution (Click here to expand)</strong></span></summary>\n",
    "\n",
    "```python\n",
    "### START CODE HERE ###\n",
    "\n",
    "# 1. Add a channel dimension at index 1.\n",
    "image_batch_with_channel = image_batch.unsqueeze(1)\n",
    "\n",
    "# 2. Transpose the tensor to move the channel dimension to the end.\n",
    "# Swap dimension 1 (channels) with dimension 3 (the last one).\n",
    "image_batch_transposed = image_batch_with_channel.transpose(1, 3)\n",
    "\n",
    "### END CODE HERE ###\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A batch of 4 grayscale images, each 3x3\n",
    "image_batch = torch.rand(4, 3, 3)\n",
    "\n",
    "print(\"ORIGINAL BATCH SHAPE:\", image_batch.shape)\n",
    "print(\"-\" * 45)\n",
    "\n",
    "### START CODE HERE ###\n",
    "\n",
    "# 1. Add a channel dimension at index 1.\n",
    "image_batch_with_channel = None\n",
    "\n",
    "# 2. Transpose the tensor to move the channel dimension to the end.\n",
    "# Swap dimension 1 (channels) with dimension 3 (the last one).\n",
    "image_batch_transposed = None\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "\n",
    "print(\"\\nSHAPE AFTER UNSQUEEZE:\", image_batch_with_channel.shape)\n",
    "print(\"SHAPE AFTER TRANSPOSE:\", image_batch_transposed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Output:\n",
    "\n",
    "```\n",
    "SHAPE AFTER UNSQUEEZE: torch.Size([4, 1, 3, 3])\n",
    "SHAPE AFTER TRANSPOSE: torch.Size([4, 3, 3, 1])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Combining and Weighting Sensor Data\n",
    "\n",
    "You're building an environment monitoring system that uses two sensors: one for temperature and one for humidity. You receive data from these sensors as two separate 1D tensors.\n",
    "\n",
    "**Your task is to**:\n",
    "\n",
    "1. **Concatenate** the two tensors into a single `2x5` tensor, where the first row is temperature data and the second is humidity data.\n",
    "2. Create a `weights` tensor `torch.tensor([0.6, 0.4])`.\n",
    "3. Use **broadcasting and element-wise multiplication** to apply these weights to the combined sensor data. The temperature data should be multiplied by 0.6 and the humidity data by 0.4.\n",
    "4. Finally, calculate the **weighted average** for each time step by **summing** the weighted values along `dim=0` and **dividing** by the sum of the weights.\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary><span style=\"color:green;\"><strong>Solution (Click here to expand)</strong></span></summary>\n",
    "\n",
    "```python\n",
    "### START CODE HERE ###\n",
    "\n",
    "# 1. Concatenate the two tensors.\n",
    "# Note: You need to unsqueeze them first to stack them vertically.\n",
    "combined_data = torch.cat((temperature.unsqueeze(0), humidity.unsqueeze(0)), dim=0)\n",
    "\n",
    "# 2. Create the weights tensor.\n",
    "weights = torch.tensor([0.6, 0.4])\n",
    "\n",
    "# 3. Apply weights using broadcasting.\n",
    "# You need to reshape weights to [2, 1] to broadcast across columns.\n",
    "weighted_data = combined_data * weights.unsqueeze(1)\n",
    "\n",
    "# 4. Calculate the weighted average for each time step.\n",
    "#    (A true average = weighted sum / sum of weights)\n",
    "weighted_sum = torch.sum(weighted_data, dim=0)\n",
    "weighted_average = weighted_sum / torch.sum(weights)\n",
    "\n",
    "### END CODE HERE ###\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sensor readings (5 time steps)\n",
    "temperature = torch.tensor([22.5, 23.1, 21.9, 22.8, 23.5])\n",
    "humidity = torch.tensor([55.2, 56.4, 54.8, 57.1, 56.8])\n",
    "\n",
    "print(\"TEMPERATURE DATA: \", temperature)\n",
    "print(\"HUMIDITY DATA:    \", humidity)\n",
    "print(\"-\" * 45)\n",
    "\n",
    "### START CODE HERE ###\n",
    "\n",
    "# 1. Concatenate the two tensors.\n",
    "# Note: You need to unsqueeze them first to stack them vertically.\n",
    "combined_data = None\n",
    "\n",
    "# 2. Create the weights tensor.\n",
    "weights = None\n",
    "\n",
    "# 3. Apply weights using broadcasting.\n",
    "# You need to reshape weights to [2, 1] to broadcast across columns.\n",
    "weighted_data = None\n",
    "\n",
    "# 4. Calculate the weighted average for each time step.\n",
    "#    (A true average = weighted sum / sum of weights)\n",
    "weighted_sum = None\n",
    "weighted_average = None\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "print(\"\\nCOMBINED DATA (2x5):\\n\\n\", combined_data)\n",
    "print(\"\\nWEIGHTED DATA:\\n\\n\", weighted_data)\n",
    "print(\"\\nWEIGHTED AVERAGE:\", weighted_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Output:\n",
    "\n",
    "```\n",
    "COMBINED DATA (2x5):\n",
    "\n",
    " tensor([[22.5000, 23.1000, 21.9000, 22.8000, 23.5000],\n",
    "        [55.2000, 56.4000, 54.8000, 57.1000, 56.8000]])\n",
    "\n",
    "WEIGHTED DATA:\n",
    "\n",
    " tensor([[13.5000, 13.8600, 13.1400, 13.6800, 14.1000],\n",
    "        [22.0800, 22.5600, 21.9200, 22.8400, 22.7200]])\n",
    "\n",
    "WEIGHTED AVERAGE: tensor([35.5800, 36.4200, 35.0600, 36.5200, 36.8200])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Feature Engineering for Taxi Fares\n",
    "\n",
    "You are working with a dataset of taxi trips. You have a tensor, `trip_data`, where each row is a trip and the columns represent **[distance (km), hour_of_day (24h)]**.\n",
    "\n",
    "**Your goal** is to engineer a new binary feature called `is_rush_hour_long_trip`. This feature should be `True` (or `1`) only if a trip meets **both** of the following criteria:\n",
    "\n",
    "* It's a **long trip** (distance > 10 km).\n",
    "* It occurs during a **rush hour** (8-10 AM or 5-7 PM, i.e., `[8, 10)` or `[17, 19)`).\n",
    "\n",
    "To achieve this, you will need to:\n",
    "\n",
    "1. **Slice** the `trip_data` tensor to isolate the `distance` and `hour` columns.\n",
    "2. Use **logical and comparison operators** to create boolean masks for each condition (long trip, morning rush, evening rush).\n",
    "3. Combine these masks to create the final `is_rush_hour_long_trip` feature.\n",
    "4. **Reshape** this new 1D feature tensor into a 2D column vector and convert its data type to float so it can be combined with the original data.\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary><span style=\"color:green;\"><strong>Solution (Click here to expand)</strong></span></summary>\n",
    "\n",
    "```python\n",
    "### START CODE HERE ###\n",
    "\n",
    "# 1. Slice the main tensor to get 1D tensors for each feature.\n",
    "distances = trip_data[:, 0]\n",
    "hours = trip_data[:, 1]\n",
    "\n",
    "# 2. Create boolean masks for each condition.\n",
    "is_long_trip = distances > 10.0\n",
    "is_morning_rush = (hours >= 8.0) & (hours < 10.0)\n",
    "is_evening_rush = (hours >= 17.0) & (hours < 19.0)\n",
    "\n",
    "# 3. Combine masks to identify rush hour long trips.\n",
    "# A trip is a rush hour long trip if it's (a morning OR evening rush) AND a long trip.\n",
    "is_rush_hour_long_trip_mask = (is_morning_rush | is_evening_rush) & is_long_trip\n",
    "\n",
    "# 4. Reshape the new feature into a column vector and cast to float.\n",
    "new_feature_col = is_rush_hour_long_trip_mask.float().unsqueeze(1)\n",
    "\n",
    "### END CODE HERE ###\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data for 8 taxi trips: [distance, hour_of_day]\n",
    "trip_data = torch.tensor([\n",
    "    [5.3, 7],   # Not rush hour, not long\n",
    "    [12.1, 9],  # Morning rush, long trip -> RUSH HOUR LONG\n",
    "    [15.5, 13], # Not rush hour, long trip\n",
    "    [6.7, 18],  # Evening rush, not long\n",
    "    [2.4, 20],  # Not rush hour, not long\n",
    "    [11.8, 17], # Evening rush, long trip -> RUSH HOUR LONG\n",
    "    [9.0, 9],   # Morning rush, not long\n",
    "    [14.2, 8]   # Morning rush, long trip -> RUSH HOUR LONG\n",
    "], dtype=torch.float32)\n",
    "\n",
    "\n",
    "print(\"ORIGINAL TRIP DATA (Distance, Hour):\\n\\n\", trip_data)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "\n",
    "### START CODE HERE ###\n",
    "\n",
    "# 1. Slice the main tensor to get 1D tensors for each feature.\n",
    "distances = None\n",
    "hours = None\n",
    "\n",
    "# 2. Create boolean masks for each condition.\n",
    "is_long_trip = None\n",
    "is_morning_rush = None\n",
    "is_evening_rush = None\n",
    "\n",
    "# 3. Combine masks to identify rush hour long trips.\n",
    "# A trip is a rush hour long trip if it's (a morning OR evening rush) AND a long trip.\n",
    "is_rush_hour_long_trip_mask = None\n",
    "\n",
    "# 4. Reshape the new feature into a column vector and cast to float.\n",
    "new_feature_col = None\n",
    "\n",
    "### END CODE HERE ###\n",
    "\n",
    "print(\"\\n'IS RUSH HOUR LONG TRIP' MASK: \", is_rush_hour_long_trip_mask)\n",
    "print(\"\\nNEW FEATURE COLUMN (Reshaped):\\n\\n\", new_feature_col)\n",
    "\n",
    "# You can now concatenate this new feature to the original data\n",
    "enhanced_trip_data = torch.cat((trip_data, new_feature_col), dim=1)\n",
    "print(\"\\nENHANCED DATA (with new feature at the end):\\n\\n\", enhanced_trip_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Output:\n",
    "\n",
    "```\n",
    "'IS RUSH HOUR LONG TRIP' MASK:  tensor([False,  True, False, False, False,  True, False,  True])\n",
    "\n",
    "NEW FEATURE COLUMN (Reshaped):\n",
    "\n",
    " tensor([[0.],\n",
    "        [1.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [1.],\n",
    "        [0.],\n",
    "        [1.]])\n",
    "\n",
    "ENHANCED DATA (with new feature at the end):\n",
    "\n",
    " tensor([[ 5.3000,  7.0000,  0.0000],\n",
    "        [12.1000,  9.0000,  1.0000],\n",
    "        [15.5000, 13.0000,  0.0000],\n",
    "        [ 6.7000, 18.0000,  0.0000],\n",
    "        [ 2.4000, 20.0000,  0.0000],\n",
    "        [11.8000, 17.0000,  1.0000],\n",
    "        [ 9.0000,  9.0000,  0.0000],\n",
    "        [14.2000,  8.0000,  1.0000]])\n",
    "```        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations on completing this lab! You have now worked through the fundamental building blocks of PyTorch. You started with an empty slate and learned to create, reshape, combine, and query tensors in various ways.\n",
    "\n",
    "The skills you have developed here are essential for every machine learning practitioner. The element-wise arithmetic and broadcasting you practiced are precisely how a neural network efficiently applies weights and biases to entire batches of data at once. The reshaping techniques like `unsqueeze` and `squeeze` are what allow you to prepare a single data point for a model that expects a batch, and then clean up the output afterward. These are not just abstract exercises; they are the day-to-day operations required to build and debug effective deep learning models.\n",
    "\n",
    "With this solid understanding of tensors, you are now fully prepared to move on to the next stage: building and training neural networks to solve even more complex problems. Every model you build from now on will stand on this foundation."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOorK7XLr3MfwWQG/E40ryg",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
